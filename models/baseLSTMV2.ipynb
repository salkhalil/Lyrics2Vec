{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>In Da Club</td>\n",
       "      <td>[Intro]\\nGo, go, go, go, go, go\\nGo Shorty, it...</td>\n",
       "      <td>50 Cent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>21 Questions</td>\n",
       "      <td>[Ad-Libs]\\nNew York City\\nYou are now rockin'\\...</td>\n",
       "      <td>50 Cent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Many Men (Wish Death)</td>\n",
       "      <td>[Skit]\\nMan, we gotta go get somethin' to eat\\...</td>\n",
       "      <td>50 Cent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>My Life</td>\n",
       "      <td>[Chorus]\\nMy, yeah, yeah, mmm\\nMy life, my lif...</td>\n",
       "      <td>50 Cent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Patiently Waiting</td>\n",
       "      <td>[Intro]\\nHey Em, you know you're my favorite w...</td>\n",
       "      <td>50 Cent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>Cruisin’</td>\n",
       "      <td>[Intro]\\n(Crusin')\\n\\n[Verse 1]\\nBaby, let's c...</td>\n",
       "      <td>Smokey Robinson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>Really Gonna Miss You</td>\n",
       "      <td>[Verse 1]\\nReally gonna miss you\\nIt's really ...</td>\n",
       "      <td>Smokey Robinson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>579</td>\n",
       "      <td>The Agony and the Ecstasy</td>\n",
       "      <td>[Verse 1]\\nWhat's it all about this crazy love...</td>\n",
       "      <td>Smokey Robinson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>582</td>\n",
       "      <td>Ooh Baby Baby</td>\n",
       "      <td>[Verse 1]\\nI did you wrong\\nMy heart went out ...</td>\n",
       "      <td>Smokey Robinson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>587</td>\n",
       "      <td>My Girl</td>\n",
       "      <td>[Intro]\\nOoh, ooh-ooh, ooh (Ooh)\\nOoh, ooh-ooh...</td>\n",
       "      <td>Smokey Robinson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    song title  \\\n",
       "0                   In Da Club   \n",
       "1                 21 Questions   \n",
       "2        Many Men (Wish Death)   \n",
       "3                      My Life   \n",
       "4            Patiently Waiting   \n",
       "..                         ...   \n",
       "575                   Cruisin’   \n",
       "576      Really Gonna Miss You   \n",
       "579  The Agony and the Ecstasy   \n",
       "582              Ooh Baby Baby   \n",
       "587                    My Girl   \n",
       "\n",
       "                                                lyrics           artist  \n",
       "0    [Intro]\\nGo, go, go, go, go, go\\nGo Shorty, it...          50 Cent  \n",
       "1    [Ad-Libs]\\nNew York City\\nYou are now rockin'\\...          50 Cent  \n",
       "2    [Skit]\\nMan, we gotta go get somethin' to eat\\...          50 Cent  \n",
       "3    [Chorus]\\nMy, yeah, yeah, mmm\\nMy life, my lif...          50 Cent  \n",
       "4    [Intro]\\nHey Em, you know you're my favorite w...          50 Cent  \n",
       "..                                                 ...              ...  \n",
       "575  [Intro]\\n(Crusin')\\n\\n[Verse 1]\\nBaby, let's c...  Smokey Robinson  \n",
       "576  [Verse 1]\\nReally gonna miss you\\nIt's really ...  Smokey Robinson  \n",
       "579  [Verse 1]\\nWhat's it all about this crazy love...  Smokey Robinson  \n",
       "582  [Verse 1]\\nI did you wrong\\nMy heart went out ...  Smokey Robinson  \n",
       "587  [Intro]\\nOoh, ooh-ooh, ooh (Ooh)\\nOoh, ooh-ooh...  Smokey Robinson  \n",
       "\n",
       "[488 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_songs = pd.read_csv('all_songs.csv')\n",
    "all_songs['artist'] = all_songs['artist'].astype('category') # convert to categorical to get numerical classes\n",
    "some_songs = all_songs.loc[all_songs['lyrics'].str.startswith('[').fillna(False)]\n",
    "some_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training samples\n",
    "X = some_songs.lyrics.values\n",
    "\n",
    "# create labels\n",
    "y = some_songs.artist.cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_verse(song, removeN = True):\n",
    "    verses = song.split('[')\n",
    "    for ind in range(1, len(verses)):\n",
    "        verses[ind] = verses[ind].split(']')[1]\n",
    "        verses[ind] = verses[ind][1:]\n",
    "        if removeN:\n",
    "            verses[ind] = re.sub('\\n', ' ', verses[ind])\n",
    "        verses[ind] = re.sub('  ', '', verses[ind])\n",
    "    return verses[1:]\n",
    "\n",
    "def split_by_bar(song, retNum = False):\n",
    "    verses = split_by_verse(song, removeN=False)\n",
    "    bars = []\n",
    "    for verse in verses:\n",
    "        t_bars = verse.split('\\n')\n",
    "        bars += t_bars[:-2]\n",
    "    if retNum:\n",
    "        return len(bars)\n",
    "    return bars\n",
    "\n",
    "def split_by_word(song, retNum = False):\n",
    "    bars = split_by_bar(song)\n",
    "    words = []\n",
    "    for bar in bars:\n",
    "        ws = bar.split(' ')\n",
    "        words += ws\n",
    "    if retNum:\n",
    "        return len(words)\n",
    "    return words\n",
    "\n",
    "def get_embeddings(msgs):\n",
    "    encoder = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "    embeddings = encoder.encode(msgs)\n",
    "    return torch.unsqueeze(torch.from_numpy(embeddings), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [03:27<00:00,  3.40s/it]\n"
     ]
    }
   ],
   "source": [
    "X = X[:488:8]\n",
    "y = y[:488:8]\n",
    "\n",
    "fail_idxs = []\n",
    "\n",
    "for ind in tqdm(range(len(X))):\n",
    "    try:\n",
    "        words = split_by_word(X[ind])\n",
    "        X[ind] = get_embeddings(words)\n",
    "    except IndexError:\n",
    "        # ignore empty inputs\n",
    "        fail_idxs.append(ind)\n",
    "        continue\n",
    "\n",
    "# delete all songs which failed to convert into embeddings\n",
    "X = np.delete(X, fail_idxs)\n",
    "y = np.delete(y, fail_idxs)\n",
    "\n",
    "# with open('embeddings.pkl', 'wb') as f:\n",
    "#     pickle.dump((X,y), f)\n",
    "    \n",
    "# with open('embeddings.pkl', 'rb') as f:\n",
    "#     X, y = pickle.load(f)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = 0.9, shuffle = True)\n",
    "\n",
    "# convert numpy ys into torch tensor\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "# Give dim for y labels\n",
    "y_train = torch.unsqueeze(y_train, 1)\n",
    "y_test = torch.unsqueeze(y_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BaseLSTM, self).__init__()\n",
    "        \n",
    "        # define parameters sizes\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # define lstm layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, 1, batch_first = True, bidirectional=False)\n",
    "\n",
    "        # define fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        #init hidden states\n",
    "        h0 = torch.zeros(1, 1, self.hidden_size)\n",
    "        c0 = torch.zeros(1, 1, self.hidden_size)\n",
    "        \n",
    "        # pass input and h0, c0 into LSTM\n",
    "        out, (h_out, c_out) = self.lstm(input, (h0, c0))\n",
    "        \n",
    "        out = out.reshape(-1, self.hidden_size)\n",
    "        out = self.fc(out)\n",
    "        artist_scores = F.softmax(out[-1], dim=0)\n",
    "        return torch.unsqueeze(artist_scores,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:21<00:00, 10.84s/it]\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model = BaseLSTM(input_size=768, hidden_size=256, output_size=13)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "model.train()\n",
    "for e in tqdm(range(2)):\n",
    "    for x, y in zip(x_train, y_train):\n",
    "        model.zero_grad()\n",
    "\n",
    "        artist_scores = model(x)\n",
    "        loss = loss_function(artist_scores, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% Test Accuracy\n"
     ]
    }
   ],
   "source": [
    "def Accuracy(xs, ys):\n",
    "    correct = 0\n",
    "    for i in range(len(xs)):\n",
    "        # run through model\n",
    "        pred = model(xs[i])\n",
    "        # softmax distribution\n",
    "        pred = nn.functional.softmax(pred[-1], dim=0).data\n",
    "        # calc argmax\n",
    "        pred = torch.argmax(pred).item()\n",
    "        # sum up correct predictions\n",
    "        correct += (pred == torch.unsqueeze(torch.argmax(ys[i]), 0))\n",
    "    return correct.item()/len(xs)\n",
    "\n",
    "test_acc = Accuracy(x_test, y_test)\n",
    "print('{}% Test Accuracy'.format(test_acc*100))\n",
    "\n",
    "train_acc = Accuracy(x_train, y_train)\n",
    "print('{}% Train Accuracy'.format(train_acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
